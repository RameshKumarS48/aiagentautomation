---
name: "LiteLLM"
category: "Deployment and Serving"
source_url: "https://github.com/BerriAI/litellm"
description: "LiteLLM is an AI agent in the Deployment and Serving category. ![](https://img.shields.io/github/stars/BerriAI/litellm.svg?cacheSeconds=86400) - LiteLLM is a Python SDK, Proxy Server (LLM Gateway) to call 100+ LLM APIs in OpenAI format - Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, Replicate, Groq."
tech_stack:
  - "Python"
  - "LLM APIs"
problem_solved: "This tool addresses challenges in the deployment and serving domain."
target_audience: "Developers and teams working with deployment and serving automation."
inputs:
  - "User configuration"
  - "API credentials (if required)"
  - "Task parameters"
outputs:
  - "Automated task results"
  - "Status reports"
  - "Generated content or actions"
workflow_steps:
  - "User configures the agent with required parameters"
  - "Agent receives input data or trigger"
  - "Agent processes the request using its core logic"
  - "Agent interacts with external services if needed"
  - "Results are returned to the user"
sample_prompt: |
  You are LiteLLM, an AI assistant. Help the user accomplish their task efficiently.
tools_used:
  - "LLM APIs"
  - "Python"
alternatives:
  - "AutoGPT"
  - "LangChain Agents"
  - "CrewAI"
is_open_source: "Yes"
can_self_host: "Yes"
skill_level: "Intermediate"
last_updated: 2026-02-15
---

<!-- Additional notes or content can go here -->
