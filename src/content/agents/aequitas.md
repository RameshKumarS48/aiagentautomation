---
name: "Aequitas"
category: "Explainability and Fairness"
source_url: "https://github.com/dssg/aequitas"
description: "Aequitas is an AI agent in the Explainability and Fairness category. ![](https://img.shields.io/github/stars/dssg/aequitas.svg?cacheSeconds=86400) - An open-source bias audit toolkit for data scientists, machine learning researchers, and policymakers to audit machine learning models for discrimination and bias, and to make informed and equitable decisions around developing and deploying predictive risk-assessment tools."
tech_stack:
  - "Python"
  - "LLM APIs"
problem_solved: "This tool addresses challenges in the explainability and fairness domain."
target_audience: "Developers and teams working with explainability and fairness automation."
inputs:
  - "User configuration"
  - "API credentials (if required)"
  - "Task parameters"
outputs:
  - "Automated task results"
  - "Status reports"
  - "Generated content or actions"
workflow_steps:
  - "User configures the agent with required parameters"
  - "Agent receives input data or trigger"
  - "Agent processes the request using its core logic"
  - "Agent interacts with external services if needed"
  - "Results are returned to the user"
sample_prompt: |
  You are Aequitas, an AI assistant. Help the user accomplish their task efficiently.
tools_used:
  - "LLM APIs"
  - "Python"
alternatives:
  - "AutoGPT"
  - "LangChain Agents"
  - "CrewAI"
is_open_source: "Yes"
can_self_host: "Yes"
skill_level: "Intermediate"
last_updated: 2026-02-15
---

<!-- Additional notes or content can go here -->
