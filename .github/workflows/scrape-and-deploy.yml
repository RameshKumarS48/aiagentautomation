name: Scrape AI Agents and Deploy

on:
  schedule:
    # Run every 12 hours at midnight and noon UTC
    - cron: '0 0,12 * * *'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write

jobs:
  scrape-and-build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install Node dependencies
        run: npm ci

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install -r scraper/requirements.txt

      - name: Run scraper with AI APIs
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          cd scraper
          python scraper.py

      - name: Clean up invalid entries
        run: |
          node scripts/cleanup-content.mjs

      - name: Build site
        run: npm run build

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add -A
          git diff --staged --quiet || git commit -m "Auto-update: Scrape new agents $(date +'%Y-%m-%d %H:%M')"
          git pull --rebase origin main || true
          git push origin main
